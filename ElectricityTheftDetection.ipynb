{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ElectricityTheftDetection",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desai-nitin/CDAC_2018/blob/master/ElectricityTheftDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "L8cCWw2Ak3e2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Electricity Theft Detection CDAC-Final Project**"
      ]
    },
    {
      "metadata": {
        "id": "o_ALurgumh0m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ***DataPreparation***"
      ]
    },
    {
      "metadata": {
        "id": "3gYeB_zinFky",
        "colab_type": "code",
        "outputId": "b51f9b5d-2957-4cfd-a8fb-0fb3c2fc73a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=---\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z11xEi8Yn9us",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Data**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "alHh0-kimJv9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/gdrive/My Drive/CDAC_18/Project/Dataset/data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lVQfPibHonaQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sample Creation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jdAWNrccotEJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_df=df.sample(n=100)\n",
        "\n",
        "sample_df.to_csv(path_or_buf=\"/content/gdrive/My Drive/CDAC_18/Project/Dataset/sampleData.csv\",header=list(df.columns.values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L3OeG9sQpJJY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data Cleaning\n",
        "---\n",
        "***Working on Sample***\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dppylS8kqPVA",
        "colab_type": "code",
        "outputId": "be6fcff4-9bca-498e-f70d-84cc4a156993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "#df = pd.DataFrame(df.iloc[:,1:].values)     # drop column 1 coz python generates index column on dataframe\n",
        "dfs=pd.read_csv(\"/content/gdrive/My Drive/CDAC_18/Project/Dataset/sampleData.csv\")\n",
        "dfs = dfs.dropna(axis='columns', how='all')\n",
        "dfs = dfs.drop(\"Unnamed: 0\", axis=1)\n",
        "\n",
        "df_iloc = dfs.iloc[:,:].values     # seperate dataframe to perform processing .. keeping df as it is to save headers\n",
        "\n",
        "from sklearn.preprocessing import Imputer,LabelEncoder\n",
        "\n",
        "consConvert=LabelEncoder()\n",
        "df_iloc[:,0]=consConvert.fit_transform(df_iloc[:,0].astype(str))    # Categorical CONS_NO to NUMERIC\n",
        "\n",
        "df_iloc = pd.DataFrame(df_iloc)\n",
        "\n",
        "df_y = pd.DataFrame(df_iloc.iloc[:,:2].values)   # consider first 2 columns \n",
        "\n",
        "df_x = pd.DataFrame(df_iloc.iloc[:,2:].values)   # consider rest all columns for moving average and normalization\n",
        "\n",
        "imputer=Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=1)   # replace NaN with mean\n",
        "\n",
        "df_x=pd.DataFrame(imputer.fit_transform(df_x))\n",
        "\n",
        "df_x = (df_x-min(df_x))/(max(df_x)-min(df_x))   # normalization of df_x which contains all numeric values of 1035 days\n",
        "\n",
        "df_iloc = [df_y,df_x]       # concatenate df_x and df_y into df_iloc \n",
        "df_iloc = pd.concat(df_iloc, axis=1,join='inner')\n",
        "\n",
        "# save dataframe as csv with headers of actual df\n",
        "df_iloc.to_csv(path_or_buf=\"/content/gdrive/My Drive/CDAC_18/Project/Dataset/FinalData.csv\", header=list(dfs.columns.values), index=False)\n",
        "\n",
        "#need to add moving avg imputation for NaN values"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FBXTT5KIlvYX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test"
      ]
    },
    {
      "metadata": {
        "id": "KzDazFREkgR-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/CDAC_18/Project/Dataset/FinalData.csv\").head() #read sample dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ARPgti5BluXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "outputId": "f50145e9-8088-46ee-9766-6a581cd26306"
      },
      "cell_type": "code",
      "source": [
        "test_df=pd.DataFrame(df.iloc[:,2:].values,columns=df.columns.values[2:])\n",
        "print(test_df)\n",
        "test_df=test_df.sort_values(by=1,axis=1)\n",
        "print(test_df)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   2014/1/1  2014/1/10  2014/1/11  2014/1/12  2014/1/13  2014/1/14  2014/1/15  \\\n",
            "0  0.005475   0.005475   0.005475   0.005475   0.005475   0.005475   0.005475   \n",
            "1  0.010136   0.010136   0.010136   0.010136   0.010136   0.010136   0.010136   \n",
            "2  0.000000   0.054205   0.064990   0.064244   0.055727   0.000000   0.000000   \n",
            "3  0.008713   0.008713   0.008713   0.008713   0.008713   0.008713   0.008713   \n",
            "4  0.005446   0.005533   0.004903   0.006192   0.005262   0.005455   0.005271   \n",
            "\n",
            "   2014/1/16  2014/1/17  2014/1/18    ...     2016/9/28  2016/9/29  2016/9/3  \\\n",
            "0   0.005475   0.005475   0.005475    ...      0.006919   0.006318  0.007335   \n",
            "1   0.010136   0.010136   0.010136    ...      0.007742   0.009050  0.009147   \n",
            "2   0.000000   0.000000   0.000000    ...      0.001153   0.001134  0.001521   \n",
            "3   0.008713   0.008713   0.008713    ...      0.001579   0.001725  0.001938   \n",
            "4   0.000000   0.005417   0.005707    ...      0.003527   0.009264  0.000659   \n",
            "\n",
            "   2016/9/30  2016/9/4  2016/9/5  2016/9/6  2016/9/7  2016/9/8  2016/9/9  \n",
            "0   0.006483  0.009777  0.006938  0.006424  0.006696  0.007219  0.007500  \n",
            "1   0.007558  0.008614  0.008789  0.010426  0.006240  0.007064  0.005494  \n",
            "2   0.001134  0.001182  0.016667  0.013091  0.014787  0.012548  0.013517  \n",
            "3   0.001860  0.001734  0.001890  0.001764  0.001802  0.002122  0.007083  \n",
            "4   0.008779  0.000640  0.000523  0.001008  0.000523  0.000504  0.000659  \n",
            "\n",
            "[5 rows x 1033 columns]\n",
            "   2014/5/9  2014/8/17  2015/1/8  2014/10/7  2014/8/20  2014/8/19  2014/8/25  \\\n",
            "0  0.004622   0.010300  0.005446   0.006560   0.006773   0.005833   0.009457   \n",
            "1  0.002277   0.002432  0.002607   0.002626   0.002762   0.002868   0.002984   \n",
            "2  0.011250   0.000998  0.012684   0.001105   0.010659   0.008353   0.015465   \n",
            "3  0.008713   0.018527  0.001337   0.002742   0.025019   0.020843   0.009874   \n",
            "4  0.003304   0.004341  0.003068   0.000843   0.004767   0.004283   0.005203   \n",
            "\n",
            "   2014/6/14  2014/11/13  2014/10/6     ...      2016/2/7  2016/8/25  \\\n",
            "0   0.008682    0.004234   0.007006     ...      0.005581   0.008178   \n",
            "1   0.003033    0.003140   0.003169     ...      0.024583   0.025184   \n",
            "2   0.001483    0.009709   0.002616     ...      0.001172   0.036347   \n",
            "3   0.008713    0.003023   0.002607     ...      0.080271   0.002306   \n",
            "4   0.005116    0.000882   0.003266     ...      0.001502   0.000746   \n",
            "\n",
            "   2016/8/16  2016/8/19  2016/8/17  2016/8/15  2015/2/9  2016/8/13  \\\n",
            "0   0.007384   0.005698   0.005572   0.009331  0.004293   0.008837   \n",
            "1   0.025281   0.025591   0.025698   0.026134  0.026841   0.027432   \n",
            "2   0.013798   0.018760   0.015504   0.017219  0.008033   0.001114   \n",
            "3   0.002297   0.002626   0.001851   0.002413  0.045659   0.002791   \n",
            "4   0.001066   0.000736   0.001047   0.000814  0.000601   0.000940   \n",
            "\n",
            "   2014/12/21  2014/12/22  \n",
            "0    0.005843    0.003227  \n",
            "1    0.028721    0.028818  \n",
            "2    0.002093    0.009012  \n",
            "3    0.024583    0.016105  \n",
            "4    0.001415    0.000785  \n",
            "\n",
            "[5 rows x 1033 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bCjIECrIsiVG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Implementing Model for sample**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gfCM_JX2UzDY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wide implementation"
      ]
    },
    {
      "metadata": {
        "id": "LKBLtsb1fTwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df=pd.DataFrame(df.iloc[:,2:].values).head()\n",
        "print(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8z798lMdMGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/CDAC_18/Project/Dataset/FinalData.csv\") #read sample dataset\n",
        "\n",
        "df_y = df.iloc[:,1].values\n",
        "df_x = df.iloc[:,2:-4].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y,train_size=0.8)\n",
        "\n",
        "layers = keras.layers\n",
        "alpha=60\n",
        "# wide model \n",
        "wideInputs = layers.Input(shape=(1029,))\n",
        "#fullyConnectedLayer = layers.Flatten()(wideInputs)\n",
        "fullyConnectedLayer = layers.Dense(alpha,activation='relu',input_shape=(1029,))(wideInputs)\n",
        "wideOutputs = layers.Dense(1, activation = 'sigmoid')(fullyConnectedLayer)\n",
        "wideModel = keras.Model(inputs = wideInputs, outputs = wideOutputs)\n",
        "wideModel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(wideModel.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y0hcy4xjLrON",
        "colab_type": "code",
        "outputId": "32ad78f5-0df8-4c07-94ed-f7dfb5044d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "cell_type": "code",
      "source": [
        "#Wide Model training\n",
        "BATCH_SIZE=516\n",
        "EPOCHS=50\n",
        "wide = wideModel.fit(x_train,y_train,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_split=0.2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 64 samples, validate on 16 samples\n",
            "Epoch 1/50\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.6987 - acc: 0.1875 - val_loss: 0.6873 - val_acc: 0.8125\n",
            "Epoch 2/50\n",
            "64/64 [==============================] - 0s 154us/step - loss: 0.6823 - acc: 0.9062 - val_loss: 0.6798 - val_acc: 0.8125\n",
            "Epoch 3/50\n",
            "64/64 [==============================] - 0s 110us/step - loss: 0.6697 - acc: 0.9062 - val_loss: 0.6721 - val_acc: 0.8125\n",
            "Epoch 4/50\n",
            "64/64 [==============================] - 0s 75us/step - loss: 0.6603 - acc: 0.9062 - val_loss: 0.6641 - val_acc: 0.8125\n",
            "Epoch 5/50\n",
            "64/64 [==============================] - 0s 112us/step - loss: 0.6516 - acc: 0.9062 - val_loss: 0.6563 - val_acc: 0.8125\n",
            "Epoch 6/50\n",
            "64/64 [==============================] - 0s 125us/step - loss: 0.6431 - acc: 0.9062 - val_loss: 0.6485 - val_acc: 0.8125\n",
            "Epoch 7/50\n",
            "64/64 [==============================] - 0s 111us/step - loss: 0.6348 - acc: 0.9062 - val_loss: 0.6409 - val_acc: 0.8125\n",
            "Epoch 8/50\n",
            "64/64 [==============================] - 0s 102us/step - loss: 0.6266 - acc: 0.9062 - val_loss: 0.6335 - val_acc: 0.8125\n",
            "Epoch 9/50\n",
            "64/64 [==============================] - 0s 100us/step - loss: 0.6186 - acc: 0.9062 - val_loss: 0.6264 - val_acc: 0.8125\n",
            "Epoch 10/50\n",
            "64/64 [==============================] - 0s 102us/step - loss: 0.6109 - acc: 0.9062 - val_loss: 0.6197 - val_acc: 0.8125\n",
            "Epoch 11/50\n",
            "64/64 [==============================] - 0s 94us/step - loss: 0.6034 - acc: 0.9062 - val_loss: 0.6132 - val_acc: 0.8125\n",
            "Epoch 12/50\n",
            "64/64 [==============================] - 0s 92us/step - loss: 0.5960 - acc: 0.9062 - val_loss: 0.6071 - val_acc: 0.8125\n",
            "Epoch 13/50\n",
            "64/64 [==============================] - 0s 98us/step - loss: 0.5890 - acc: 0.9062 - val_loss: 0.6014 - val_acc: 0.8125\n",
            "Epoch 14/50\n",
            "64/64 [==============================] - 0s 74us/step - loss: 0.5823 - acc: 0.9062 - val_loss: 0.5960 - val_acc: 0.8125\n",
            "Epoch 15/50\n",
            "64/64 [==============================] - 0s 90us/step - loss: 0.5759 - acc: 0.9062 - val_loss: 0.5911 - val_acc: 0.8125\n",
            "Epoch 16/50\n",
            "64/64 [==============================] - 0s 78us/step - loss: 0.5697 - acc: 0.9062 - val_loss: 0.5865 - val_acc: 0.8125\n",
            "Epoch 17/50\n",
            "64/64 [==============================] - 0s 72us/step - loss: 0.5639 - acc: 0.9062 - val_loss: 0.5824 - val_acc: 0.8125\n",
            "Epoch 18/50\n",
            "64/64 [==============================] - 0s 85us/step - loss: 0.5583 - acc: 0.9062 - val_loss: 0.5787 - val_acc: 0.8125\n",
            "Epoch 19/50\n",
            "64/64 [==============================] - 0s 105us/step - loss: 0.5529 - acc: 0.9062 - val_loss: 0.5754 - val_acc: 0.8125\n",
            "Epoch 20/50\n",
            "64/64 [==============================] - 0s 106us/step - loss: 0.5478 - acc: 0.9062 - val_loss: 0.5725 - val_acc: 0.8125\n",
            "Epoch 21/50\n",
            "64/64 [==============================] - 0s 96us/step - loss: 0.5430 - acc: 0.9062 - val_loss: 0.5699 - val_acc: 0.8125\n",
            "Epoch 22/50\n",
            "64/64 [==============================] - 0s 117us/step - loss: 0.5383 - acc: 0.9062 - val_loss: 0.5677 - val_acc: 0.8125\n",
            "Epoch 23/50\n",
            "64/64 [==============================] - 0s 117us/step - loss: 0.5339 - acc: 0.9062 - val_loss: 0.5658 - val_acc: 0.8125\n",
            "Epoch 24/50\n",
            "64/64 [==============================] - 0s 102us/step - loss: 0.5296 - acc: 0.9062 - val_loss: 0.5642 - val_acc: 0.8125\n",
            "Epoch 25/50\n",
            "64/64 [==============================] - 0s 114us/step - loss: 0.5254 - acc: 0.9062 - val_loss: 0.5627 - val_acc: 0.8125\n",
            "Epoch 26/50\n",
            "64/64 [==============================] - 0s 82us/step - loss: 0.5214 - acc: 0.9062 - val_loss: 0.5615 - val_acc: 0.8125\n",
            "Epoch 27/50\n",
            "64/64 [==============================] - 0s 116us/step - loss: 0.5175 - acc: 0.9062 - val_loss: 0.5605 - val_acc: 0.8125\n",
            "Epoch 28/50\n",
            "64/64 [==============================] - 0s 115us/step - loss: 0.5137 - acc: 0.9062 - val_loss: 0.5596 - val_acc: 0.8125\n",
            "Epoch 29/50\n",
            "64/64 [==============================] - 0s 111us/step - loss: 0.5100 - acc: 0.9062 - val_loss: 0.5590 - val_acc: 0.8125\n",
            "Epoch 30/50\n",
            "64/64 [==============================] - 0s 76us/step - loss: 0.5063 - acc: 0.9062 - val_loss: 0.5584 - val_acc: 0.8125\n",
            "Epoch 31/50\n",
            "64/64 [==============================] - 0s 192us/step - loss: 0.5027 - acc: 0.9062 - val_loss: 0.5580 - val_acc: 0.8125\n",
            "Epoch 32/50\n",
            "64/64 [==============================] - 0s 124us/step - loss: 0.4992 - acc: 0.9062 - val_loss: 0.5576 - val_acc: 0.8125\n",
            "Epoch 33/50\n",
            "64/64 [==============================] - 0s 142us/step - loss: 0.4957 - acc: 0.9062 - val_loss: 0.5573 - val_acc: 0.8125\n",
            "Epoch 34/50\n",
            "64/64 [==============================] - 0s 122us/step - loss: 0.4922 - acc: 0.9062 - val_loss: 0.5571 - val_acc: 0.8125\n",
            "Epoch 35/50\n",
            "64/64 [==============================] - 0s 105us/step - loss: 0.4887 - acc: 0.9062 - val_loss: 0.5568 - val_acc: 0.8125\n",
            "Epoch 36/50\n",
            "64/64 [==============================] - 0s 104us/step - loss: 0.4853 - acc: 0.9062 - val_loss: 0.5567 - val_acc: 0.8125\n",
            "Epoch 37/50\n",
            "64/64 [==============================] - 0s 109us/step - loss: 0.4818 - acc: 0.9062 - val_loss: 0.5566 - val_acc: 0.8125\n",
            "Epoch 38/50\n",
            "64/64 [==============================] - 0s 118us/step - loss: 0.4784 - acc: 0.9062 - val_loss: 0.5565 - val_acc: 0.8125\n",
            "Epoch 39/50\n",
            "64/64 [==============================] - 0s 127us/step - loss: 0.4750 - acc: 0.9062 - val_loss: 0.5564 - val_acc: 0.8125\n",
            "Epoch 40/50\n",
            "64/64 [==============================] - 0s 109us/step - loss: 0.4715 - acc: 0.9062 - val_loss: 0.5564 - val_acc: 0.8125\n",
            "Epoch 41/50\n",
            "64/64 [==============================] - 0s 119us/step - loss: 0.4681 - acc: 0.9062 - val_loss: 0.5563 - val_acc: 0.8125\n",
            "Epoch 42/50\n",
            "64/64 [==============================] - 0s 112us/step - loss: 0.4646 - acc: 0.9062 - val_loss: 0.5562 - val_acc: 0.8125\n",
            "Epoch 43/50\n",
            "64/64 [==============================] - 0s 112us/step - loss: 0.4612 - acc: 0.9062 - val_loss: 0.5561 - val_acc: 0.8125\n",
            "Epoch 44/50\n",
            "64/64 [==============================] - 0s 113us/step - loss: 0.4577 - acc: 0.9062 - val_loss: 0.5560 - val_acc: 0.8125\n",
            "Epoch 45/50\n",
            "64/64 [==============================] - 0s 106us/step - loss: 0.4542 - acc: 0.9062 - val_loss: 0.5559 - val_acc: 0.8125\n",
            "Epoch 46/50\n",
            "64/64 [==============================] - 0s 98us/step - loss: 0.4507 - acc: 0.9062 - val_loss: 0.5558 - val_acc: 0.8125\n",
            "Epoch 47/50\n",
            "64/64 [==============================] - 0s 109us/step - loss: 0.4471 - acc: 0.9062 - val_loss: 0.5556 - val_acc: 0.8125\n",
            "Epoch 48/50\n",
            "64/64 [==============================] - 0s 120us/step - loss: 0.4436 - acc: 0.9062 - val_loss: 0.5555 - val_acc: 0.8125\n",
            "Epoch 49/50\n",
            "64/64 [==============================] - 0s 124us/step - loss: 0.4401 - acc: 0.9062 - val_loss: 0.5553 - val_acc: 0.8125\n",
            "Epoch 50/50\n",
            "64/64 [==============================] - 0s 109us/step - loss: 0.4365 - acc: 0.9062 - val_loss: 0.5551 - val_acc: 0.8125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yjC-iL0j28e0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction=wideModel.predict(x_test,verbose=1,batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dL-IUfsV7ZzD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Deep CNN Model Implementation***"
      ]
    },
    {
      "metadata": {
        "id": "8diZGwiP7Yxe",
        "colab_type": "code",
        "outputId": "c40fca67-619a-4af4-a4c5-51c8a8446c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "BETA=64\n",
        "GAMMA=10\n",
        "\n",
        "deepmodel = keras.models.Sequential()\n",
        "deepmodel.add(layers.Reshape((147,7),input_shape=(1029,)))\n",
        "deepmodel.add(layers.Conv1D(7,7,activation='relu',input_shape=(147,7)))\n",
        "deepmodel.add(layers.MaxPool1D(7))\n",
        "deepmodel.add(layers.Dense(BETA,activation='relu'))\n",
        "deepmodel.add(layers.Flatten())\n",
        "deepmodel.add(layers.Dense(1,activation='sigmoid'))\n",
        "deepmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(deepmodel.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 147, 7)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 141, 7)            350       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 20, 7)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 20, 64)            512       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,143\n",
            "Trainable params: 2,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xHZnGdAfbUCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "deepmodel.fit(x_train,y_train,epochs=EPOCHS,validation_split=0.2,batch_size=1029,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POQdkhAOswl1",
        "colab_type": "code",
        "outputId": "e3a49dcc-6f3b-45d2-841b-4af1827dd0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(wideModel.input,\"\",deepmodel.input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"input_16:0\", shape=(?, 1029), dtype=float32)  Tensor(\"reshape_18_input:0\", shape=(?, 1029), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TrbtIvwSpTuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mergedOutput = layers.concatenate([wideModel.output,deepmodel.output])\n",
        "mergedOutput = layers.Dense(1,activation='sigmoid')(mergedOutput)\n",
        "\n",
        "combinedModel = keras.Model(wideModel.input + [deepmodel.input], mergedOutput)\n",
        "print(combineModel.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
